"""
MotionLab AI - LLM í”¼ë“œë°± ìƒì„± (YAML í”„ë¡¬í”„íŠ¸ + ìë™ ë²„ì „ ê´€ë¦¬)
"""

import json
from typing import Dict, Any, List

from openai import AsyncOpenAI

from config import get_settings
from core.prompts.loader import prompt_loader
from utils.logger import logger
from utils.exceptions import (
    LLMGenerationError,
    LLMParseError,
    LLMInvalidResponseError,
)


class LLMFeedback:
    """OpenAI GPT-4o-minië¥¼ ì‚¬ìš©í•œ í”¼ë“œë°± ìƒì„±"""

    def __init__(self):
        """LLMFeedback ì´ˆê¸°í™”"""
        settings = get_settings()
        self.noop_mode = settings.ENABLE_LLM_NOOP

        if not self.noop_mode:
            self.client = AsyncOpenAI(api_key=settings.openai_api_key)
            self.model = "gpt-4o-mini"
            logger.info(f"âœ… LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”: model={self.model}")
        else:
            self.client = None
            self.model = None
            logger.warning("âš ï¸ LLM NOOP ëª¨ë“œ í™œì„±í™” (ê·œì¹™ ê¸°ë°˜ í”¼ë“œë°± ì‚¬ìš©)")

        logger.info(f"âœ… LLMFeedback ì´ˆê¸°í™”: model={self.model}")

    async def generate_feedback(
        self,
        sport_type: str,
        sub_category: str,
        angles: Dict[str, float],
        phases: List[Dict[str, Any]],
        sport_config: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """LLM í”¼ë“œë°± ìƒì„±"""

        if self.noop_mode:
            logger.info("ğŸ”„ NOOP ëª¨ë“œ: ê·œì¹™ ê¸°ë°˜ í”¼ë“œë°± ìƒì„±")
            return self._generate_rule_based_feedback(
                sport_type=sport_type,
                sub_category=sub_category,
                angles=angles,
                phases=phases,
                sport_config=sport_config,
            )

        try:
            messages = self._build_prompt(sport_type, sub_category, angles, phases)

            logger.info(
                f"ğŸ“¤ LLM í˜¸ì¶œ: {sport_type}/{sub_category}, "
                f"prompt_version={messages['version']}"
            )

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": messages["system"]},
                    {"role": "user", "content": messages["user"]},
                ],
                response_format={"type": "json_object"},
                temperature=0.7,
                max_tokens=1000,
            )

            content = response.choices[0].message.content

            # ========== JSON íŒŒì‹± ì˜ˆì™¸ ì²˜ë¦¬ ê°œì„  ==========
            try:
                result = json.loads(content)
            except json.JSONDecodeError as e:
                logger.error(f"âŒ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
                raise LLMParseError(
                    details=f"Invalid JSON from LLM: {str(e)}, response: {content[:200]}"
                )

            # ========== ì‘ë‹µ êµ¬ì¡° ê²€ì¦ ==========
            required_keys = ["feedback", "overall_score", "improvements"]
            missing_keys = [key for key in required_keys if key not in result]
            if missing_keys:
                logger.error(f"âŒ LLM ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: missing keys={missing_keys}")
                raise LLMInvalidResponseError(
                    details=f"Missing required keys: {missing_keys}"
                )

            result["prompt_version"] = messages["version"]

            logger.info(
                f"âœ… LLM ì‘ë‹µ: score={result.get('overall_score')}, "
                f"version={messages['version']}"
            )

            return result

        except (LLMParseError, LLMInvalidResponseError):
            raise

        except Exception as e:
            logger.error(f"âŒ LLM í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            raise LLMGenerationError(
                details=f"Unexpected error during LLM generation: {str(e)}"
            )

    def _build_prompt(
        self,
        sport_type: str,
        sub_category: str,
        angles: Dict[str, float],
        phases: List[Dict[str, Any]],
    ) -> Dict[str, str]:
        """
        í”„ë¡¬í”„íŠ¸ ìƒì„± (YAML ê¸°ë°˜ + Git ë²„ì „ ìë™).

        Before (í•˜ë“œì½”ë”©): 200ì¤„ì˜ if-else ì§€ì˜¥ + ìˆ˜ë™ ë²„ì „ ê´€ë¦¬

        After (YAML + Git): 1ì¤„ë¡œ í•´ê²° + ìë™ ë²„ì „ ê´€ë¦¬
        """
        # anglesë¥¼ List[Dict]ë¡œ ë³€í™˜ (YAML í”„ë¡¬í”„íŠ¸ í˜¸í™˜)
        angles_list = [{"name": name, "value": value} for name, value in angles.items()]

        return prompt_loader.load(
            sport_type=sport_type,
            sub_category=sub_category,
            context={"angles": angles_list, "phases": phases},
        )

    def _generate_rule_based_feedback(
        self,
        sport_type: str,
        sub_category: str,
        angles: Dict[str, float],
        phases: List[Dict[str, Any]],
        sport_config: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """ê·œì¹™ ê¸°ë°˜ í”¼ë“œë°± (JSONì˜ angle_validation ì‚¬ìš©)"""
        if not angles:
            return {
                "overall_score": 50,
                "feedback": "ê°ë„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "improvements": [
                    {
                        "issue": "ê°ë„ ë°ì´í„° ë¶€ì¡±",
                        "suggestion": "ì˜ìƒì—ì„œ ì‹ ì²´ê°€ ëª…í™•íˆ ë³´ì´ë„ë¡ ì´¬ì˜í•´ì£¼ì„¸ìš”",
                    }
                ],
                "prompt_version": "noop",
            }

        if not sport_config or "angle_validation" not in sport_config:
            logger.error(
                f"âŒ sport_config ë˜ëŠ” angle_validation ëˆ„ë½: {sport_type}/{sub_category}"
            )
            raise ValueError(
                f"sport_config.angle_validationì´ í•„ìš”í•©ë‹ˆë‹¤: {sport_type}/{sub_category}"
            )

        validation = sport_config["angle_validation"]
        min_normal = validation["min_normal"]
        max_normal = validation["max_normal"]
        score_good = validation["score_good"]
        score_warning = validation["score_warning"]

        angle_scores = []
        good_points = []
        improvements = []

        # Dict ìˆœíšŒ
        for angle_name, angle_value in angles.items():
            if min_normal <= angle_value <= max_normal:
                angle_scores.append(score_good)
                good_points.append(f"{angle_name}: {angle_value:.1f}ë„ (ì–‘í˜¸)")
            else:
                angle_scores.append(score_warning)
                improvements.append(
                    {
                        "issue": f"{angle_name} ë²”ìœ„ ì´íƒˆ",
                        "current_value": angle_value,
                        "ideal_range": [min_normal, max_normal],
                        "suggestion": f"{angle_name}ì„(ë¥¼) {min_normal}~{max_normal}ë„ ë²”ìœ„ë¡œ ì¡°ì •í•´ì£¼ì„¸ìš”",
                    }
                )

        overall_score = sum(angle_scores) // len(angle_scores) if angle_scores else 70

        feedback_parts = []
        if good_points:
            feedback_parts.append(f"âœ… {good_points[0]}")
        if improvements:
            feedback_parts.append(f"ğŸ“Œ {improvements[0]['issue']}")

        feedback = (
            " | ".join(feedback_parts)
            if feedback_parts
            else f"[Noop] {sport_type}/{sub_category} ë¶„ì„ ì™„ë£Œ"
        )

        logger.info(f"âœ… ê·œì¹™ ê¸°ë°˜ í”¼ë“œë°±: score={overall_score}")

        return {
            "overall_score": overall_score,
            "feedback": feedback,
            "improvements": (
                improvements[:3]
                if improvements
                else [
                    {"issue": "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸", "suggestion": "í˜„ì¬ ìì„¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”"}
                ]
            ),
            "prompt_version": "noop",
        }
