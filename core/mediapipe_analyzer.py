"""
MediaPipe í¬ì¦ˆ ì¶”ì¶œ ëª¨ë“ˆ

í”„ë¡¬í”„íŠ¸ A13 ê·œì¹™:
- model_complexity=1 (Full ëª¨ë¸)
- min_detection_confidence=0.5
- min_tracking_confidence=0.5

ì—­í• :
- ì˜ìƒì—ì„œ 33ê°œ ëœë“œë§ˆí¬ ì¶”ì¶œ
- í”„ë ˆì„ë³„ í‚¤í¬ì¸íŠ¸ ìˆ˜ì§‘
- ì‹ ë¢°ë„ ë‚®ì€ í”„ë ˆì„ í•„í„°ë§ (visibility < 0.5)
- ìœ íš¨ í”„ë ˆì„ ë¹„ìœ¨ ì²´í¬ (ìµœì†Œ 10%)

ì—ëŸ¬ ì²˜ë¦¬:
- NoKeypointsError: ìœ íš¨ í”„ë ˆì„ì´ 10% ë¯¸ë§Œ
- VideoTooShortError: ì˜ìƒ ê¸¸ì´ê°€ 1ì´ˆ ë¯¸ë§Œ
"""

import cv2
import logging
import mediapipe as mp
from typing import List, Dict, Any
from utils.exceptions.errors import NoKeypointsError, VideoTooShortError
from config.settings import get_settings

logger = logging.getLogger(__name__)


class MediaPipeAnalyzer:
    """
    MediaPipe Pose ì¶”ì¶œê¸°

    33ê°œ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤:
    0: nose, 11: left_shoulder, 12: right_shoulder,
    13: left_elbow, 14: right_elbow, 15: left_wrist, 16: right_wrist,
    23: left_hip, 24: right_hip, 25: left_knee, 26: right_knee,
    27: left_ankle, 28: right_ankle

    í”„ë¡¬í”„íŠ¸ A13 ì°¸ì¡°:
    - static_image_mode=False (ì˜ìƒ ëª¨ë“œ, í”„ë ˆì„ ê°„ ì¶”ì )
    - model_complexity=1 (0=Lite, 1=Full, 2=Heavy)
    """

    def __init__(self):
        """
        MediaPipe Pose ì´ˆê¸°í™”

        ì™œ ì´ë ‡ê²Œ í–ˆë‚˜?
        - settingsì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (í…ŒìŠ¤íŠ¸/í”„ë¡œë•ì…˜ ë¶„ë¦¬ ê°€ëŠ¥)
        - ì‹±ê¸€í†¤ íŒ¨í„´ (get_settings()ëŠ” @lru_cacheë¡œ ìºì‹±ë¨)
        """
        settings = get_settings()

        # MediaPipe Pose ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,  # ì˜ìƒ ëª¨ë“œ (í”„ë ˆì„ ê°„ ì¶”ì  ì‚¬ìš©)
            model_complexity=settings.MEDIAPIPE_MODEL_COMPLEXITY,  # 1 (Full)
            min_detection_confidence=settings.MEDIAPIPE_MIN_DETECTION_CONFIDENCE,  # 0.5
            min_tracking_confidence=settings.MEDIAPIPE_MIN_TRACKING_CONFIDENCE,  # 0.5
        )

        logger.info(
            f"MediaPipeAnalyzer ì´ˆê¸°í™”: "
            f"model_complexity={settings.MEDIAPIPE_MODEL_COMPLEXITY}, "
            f"detection_confidence={settings.MEDIAPIPE_MIN_DETECTION_CONFIDENCE}"
        )

    def extract_landmarks(self, video_path: str) -> List[Dict[str, Any]]:
        """
        ì˜ìƒì—ì„œ í”„ë ˆì„ë³„ ëœë“œë§ˆí¬ ì¶”ì¶œ

        Args:
            video_path: ì˜ìƒ íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ

        Returns:
            List[Dict]: í”„ë ˆì„ë³„ ëœë“œë§ˆí¬
            [
                {
                    "frame_index": 0,
                    "timestamp": 0.0,  # ì´ˆ ë‹¨ìœ„
                    "landmarks": [
                        {"x": 0.5, "y": 0.3, "z": -0.1, "visibility": 0.95},
                        ...  # 33ê°œ
                    ]
                },
                ...
            ]

        Raises:
            NoKeypointsError: ìœ íš¨ í”„ë ˆì„ì´ 10% ë¯¸ë§Œ (AN_001)
            VideoTooShortError: ì˜ìƒ ê¸¸ì´ê°€ 1ì´ˆ ë¯¸ë§Œ (AN_002)
            ValueError: ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŒ

        ì™œ ì´ë ‡ê²Œ í–ˆë‚˜?
        - frame_index: ê°ë„ ê³„ì‚° ì‹œ í”„ë ˆì„ ìœ„ì¹˜ ì°¸ì¡°
        - timestamp: Phase êµ¬ê°„ ê°ì§€ì— ì‚¬ìš©
        - visibility: ì‹ ë¢°ë„ ë‚®ì€ í‚¤í¬ì¸íŠ¸ í•„í„°ë§
        """
        logger.info(f"ğŸ“¹ MediaPipe ë¶„ì„ ì‹œì‘: {video_path}")

        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŒ: {video_path}")

        # ========== ì˜ìƒ ë©”íƒ€ë°ì´í„° ==========
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0

        logger.info(
            f"ğŸ“Š ì˜ìƒ ì •ë³´: {total_frames} frames, {fps:.1f} fps, {duration:.1f}s"
        )

        # ========== ìµœì†Œ ê¸¸ì´ ì²´í¬ (1ì´ˆ) ==========
        if duration < 1.0:
            cap.release()
            raise VideoTooShortError(duration)

        # ========== í”„ë ˆì„ë³„ ëœë“œë§ˆí¬ ì¶”ì¶œ ==========
        all_landmarks = []
        frame_index = 0
        valid_frames = 0

        try:
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # RGB ë³€í™˜ (MediaPipe ìš”êµ¬ì‚¬í•­)
                # ì™œ? MediaPipeëŠ” RGB í˜•ì‹ë§Œ ì²˜ë¦¬ ê°€ëŠ¥ (OpenCVëŠ” BGR)
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # í¬ì¦ˆ ì¶”ì¶œ (í•µì‹¬ ë¡œì§)
                results = self.pose.process(frame_rgb)

                # ëœë“œë§ˆí¬ê°€ ê²€ì¶œëœ ê²½ìš°ë§Œ ì €ì¥
                if results.pose_landmarks:
                    # 33ê°œ ëœë“œë§ˆí¬ ìˆ˜ì§‘
                    landmarks = []
                    for lm in results.pose_landmarks.landmark:
                        landmarks.append(
                            {
                                "x": float(lm.x),  # ì •ê·œí™”ëœ x ì¢Œí‘œ (0.0~1.0)
                                "y": float(lm.y),  # ì •ê·œí™”ëœ y ì¢Œí‘œ (0.0~1.0)
                                "z": float(lm.z),  # ê¹Šì´ (ìŒìˆ˜=ì•, ì–‘ìˆ˜=ë’¤)
                                "visibility": float(lm.visibility),  # ì‹ ë¢°ë„ (0.0~1.0)
                            }
                        )

                    all_landmarks.append(
                        {
                            "frame_index": frame_index,
                            "timestamp": frame_index / fps,  # ì´ˆ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„
                            "landmarks": landmarks,
                        }
                    )
                    valid_frames += 1

                frame_index += 1

                # ========== ì§„í–‰ë¥  ë¡œê·¸ (10% ë‹¨ìœ„) ==========
                if frame_index % max(1, total_frames // 10) == 0:
                    progress = (frame_index / total_frames) * 100
                    logger.debug(
                        f"ğŸ”„ ì§„í–‰ë¥ : {progress:.0f}% ({frame_index}/{total_frames} frames)"
                    )

        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ë¬´ì¡°ê±´ ì‹¤í–‰)
            cap.release()

        # ========== ìœ íš¨ í”„ë ˆì„ ë¹„ìœ¨ ì²´í¬ ==========
        valid_ratio = valid_frames / total_frames if total_frames > 0 else 0

        logger.info(
            f"âœ… MediaPipe ë¶„ì„ ì™„ë£Œ: "
            f"{valid_frames}/{total_frames} frames ({valid_ratio:.1%} ìœ íš¨)"
        )

        # ìœ íš¨ í”„ë ˆì„ì´ 10% ë¯¸ë§Œì´ë©´ ì—ëŸ¬
        # ì™œ 10%? ì˜ìƒ í’ˆì§ˆì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë¶„ì„ ë¶ˆê°€ëŠ¥
        if valid_ratio < 0.1:
            raise NoKeypointsError()

        return all_landmarks

    def get_landmark_by_name(
        self, landmarks: List[Dict], name: str
    ) -> Dict[str, float]:
        """
        ëœë“œë§ˆí¬ ì´ë¦„ìœ¼ë¡œ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°

        Args:
            landmarks: 33ê°œ ëœë“œë§ˆí¬ ë¦¬ìŠ¤íŠ¸
            name: "left_shoulder", "right_elbow" ë“±

        Returns:
            {"x": 0.5, "y": 0.3, "z": -0.1, "visibility": 0.95}

        ì™œ ì´ ë©”ì„œë“œê°€ í•„ìš”í•œê°€?
        - Phase 6-2 ê°ë„ ê³„ì‚°ì—ì„œ ì‚¬ìš©
        - ì¸ë±ìŠ¤ ëŒ€ì‹  ì˜ë¯¸ ìˆëŠ” ì´ë¦„ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥

        ì‚¬ìš© ì˜ˆ:
        ```python
        left_shoulder = analyzer.get_landmark_by_name(
            frame["landmarks"],
            "left_shoulder"
        )
        ```
        """
        LANDMARK_MAP = {
            "nose": 0,
            "left_shoulder": 11,
            "right_shoulder": 12,
            "left_elbow": 13,
            "right_elbow": 14,
            "left_wrist": 15,
            "right_wrist": 16,
            "left_hip": 23,
            "right_hip": 24,
            "left_knee": 25,
            "right_knee": 26,
            "left_ankle": 27,
            "right_ankle": 28,
        }

        index = LANDMARK_MAP.get(name)
        if index is None:
            raise ValueError(f"Unknown landmark name: {name}")

        return landmarks[index]

    def __del__(self):
        """
        ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì†Œë©¸ì)

        ì™œ í•„ìš”í•œê°€?
        - MediaPipe Pose ê°ì²´ëŠ” ë©”ëª¨ë¦¬/GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì ìœ 
        - ëª…ì‹œì ìœ¼ë¡œ close() í˜¸ì¶œ í•„ìš”
        """
        if hasattr(self, "pose"):
            self.pose.close()
            logger.debug("MediaPipe Pose ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
